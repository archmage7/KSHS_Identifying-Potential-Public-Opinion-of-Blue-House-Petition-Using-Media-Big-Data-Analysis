{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hbg13\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "import math, sys, re,time, random, pprint, urllib3, requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from konlpy.tag import Twitter\n",
    "from bs4 import BeautifulSoup\n",
    "import csv, itertools, sys\n",
    "twitter = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#리스트 초기화\n",
    "nlist=[] \n",
    "List=[]\n",
    "\n",
    "# 쿼리에 검색어 입력, 검색 시작날짜와 끝 날짜 지정\n",
    "query = \"학교 몰카\"   # url 인코딩 에러는 encoding parse.quote(query) \n",
    "s_date = \"2018.08.16\" \n",
    "e_date = \"2018.09.14\" \n",
    "s_from = s_date.replace(\".\",\"\") \n",
    "e_to = e_date.replace(\".\",\"\") \n",
    "\n",
    "# 저장 경로 지정\n",
    "f = open(\"C:/Users/hbg13/Desktop/카다뷔치.댓글파일/\" + query + '뉴스댓글0001.txt', 'w', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(n_url): \n",
    "    news_detail = []\n",
    "    nlist.append(n_url) \n",
    "    breq = requests.get(n_url) \n",
    "    bsoup = BeautifulSoup(breq.content, 'html.parser') \n",
    "\n",
    "    # html 파싱 \n",
    "    title = bsoup.select('h3#articleTitle')[0].text \n",
    "    news_detail.append(title) \n",
    "\n",
    "    # 날짜 파싱\n",
    "    pdate = bsoup.select('.t11')[0].get_text()[:11] \n",
    "    news_detail.append(pdate)  \n",
    "\n",
    "    # 신문사 크롤링\n",
    "    pcompany = bsoup.select('#footer address')[0].a.get_text() \n",
    "    news_detail.append(pcompany) \n",
    "\n",
    "    return news_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 페이지 지정\n",
    "num_pages = 1\n",
    "while num_pages < 100:         \n",
    "    url = \"https://search.naver.com/search.naver?where=news&query=\" + query + \"&sort=2&ds=\" + s_date + \"&de=\" + e_date + \"&nso=so%3Ar%2Cp%3Afrom\" + s_from + \"to\" + e_to + \"%2Ca%3A&start=\" + str(num_pages) \n",
    "    #header 추가 \n",
    "    header = { \n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36', \n",
    "    } \n",
    "    req = requests.get(url,headers=header) \n",
    "    cont = req.content \n",
    "    soup = BeautifulSoup(cont, 'html.parser')\n",
    "    \n",
    "    for urls in soup.select(\"._sp_each_url\"): \n",
    "        try : \n",
    "            if urls[\"href\"].startswith(\"https://news.naver.com\"):\n",
    "                news_detail = get_news(urls[\"href\"]) \n",
    "                f.write(\"Date-\"+news_detail[1]+\"\\n\")\n",
    "                \n",
    "                oid=urls[\"href\"].split(\"oid=\")[1].split(\"&\")[0] \n",
    "                aid=urls[\"href\"].split(\"aid=\")[1] \n",
    "                page=1     \n",
    "                header = { \n",
    "                    \"User-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36\", \n",
    "                    \"referer\":urls[\"href\"], \n",
    "                }  \n",
    "                while True : \n",
    "                    c_url=\"https://apis.naver.com/commentBox/cbox/web_neo_list_jsonp.json?ticket=news&templateId=default_society&pool=cbox5&_callback=jQuery1707138182064460843_1523512042464&lang=ko&country=&objectId=news\"+oid+\"%2C\"+aid+\"&categoryId=&pageSize=20&indexSize=10&groupId=&listType=OBJECT&pageType=more&page=\"+str(page)+\"&refresh=false&sort=FAVORITE\"\n",
    "                    r=requests.get(c_url,headers=header) \n",
    "                    cont=BeautifulSoup(r.content,\"html.parser\")     \n",
    "                    total_comm=str(cont).split('comment\":')[1].split(\",\")[0] \n",
    "\n",
    "                    match=re.findall('\"contents\":([^\\*]*),\"userIdNo\"', str(cont)) \n",
    "                    # 댓글을 리스트에 중첩\n",
    "                    List.append(match) \n",
    "                    # 한 페이지에 댓글 20개 보임.\n",
    "                    if int(total_comm) <= ((page) * 20): \n",
    "                        break \n",
    "                    else :  \n",
    "                        page+=1\n",
    "                for text in List:\n",
    "                    for i, t in enumerate(text):\n",
    "                        f.write(str(i+1)+\" : \"+t+\"\\n\")\n",
    "                        i+=1\n",
    "                List=[]\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            continue          \n",
    "    num_pages = num_pages + 10\n",
    "f.write(\"Date-2000-13-23\")\n",
    "f.close()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counting(te, wr,i, cnt):\n",
    "    if(te.find(wr,i) == -1):\n",
    "        return cnt\n",
    "    return counting(te,wr,te.find(wr,i)+1, cnt+1)\n",
    "emt ={'anger':0,'disgust':0,'fear':0, 'happiness':0, 'surprise':0,'sadness':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "anger=list()\n",
    "disgust=list()\n",
    "fear = list()\n",
    "happiness = list()\n",
    "surprise = list()\n",
    "sadness = list()\n",
    "daily = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnamelist = {\"anger.txt\":'', \"disgust.txt\":'', \"fear.txt\":'', \"happiness.txt\":'', \"surprise.txt\":'', \"sadness.txt\":''}\n",
    "\n",
    "for fname in fnamelist:  \n",
    "            word_dict = open(fname, \"r\",encoding = \"utf-8\").read()\n",
    "            word_dict = word_dict.split(\"\\n\")\n",
    "            word = word_dict[0].split('\t')\n",
    "            wordic = []\n",
    "            for word in word_dict:\n",
    "                wordic.append(word.split('\t'))\n",
    "            for i in range(5000):\n",
    "                try :\n",
    "                    wordic[i][1] = float(wordic[i][1])\n",
    "                except:\n",
    "                    break\n",
    "            fnamelist[fname] = wordic     #여기는 일단 그냥 감성 단어, score 리스트 만든거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def writing(query):\n",
    "    date = ''\n",
    "    cnt2 = 0\n",
    "    f = open(\"C:/Users/hbg13/Desktop/카다뷔치.댓글파일/\" + query + '뉴스댓글0001.txt', 'r', encoding='utf-8')\n",
    "    while True:\n",
    "        text = f.readline()   #한줄 한줄..읽음.\n",
    "        if(text.find(\"Date\")==0):     #각 기사 댓글 시작 전에 Date-2012-12-31 이런식으로 있어서 음음..\n",
    "            continue\n",
    "            \n",
    "        if not text:    #뉴스 댓글 끝나면 while 문 종료\n",
    "            break\n",
    "        \n",
    "        for fname in fnamelist:\n",
    "            score = 0   \n",
    "            for elem in fnamelist[fname]:           \n",
    "                try : \n",
    "                    score += elem[1]*counting(text, elem[0], 0, 0)   \n",
    "                except : \n",
    "                    score = score\n",
    "            score  =  score*10000   #score가 너무 작아서 10000곱합\n",
    "            uname = fname.replace(\".txt\",'')\n",
    "            emt[uname] += score\n",
    "            cnt2 = cnt2 + 1\n",
    "            \n",
    "    for v in emt:    #emt에 각 감정당 score가 저장되어 있고, emt[v] = v의 score 값\n",
    "        emt[v] = emt[v]/cnt2   #평균치 ㄱㄱ\n",
    "    anger.append(emt['anger'])    #excell 로 저장하려면 list 형태로 저장하는 게 편해서..\n",
    "    disgust.append(emt['disgust'])\n",
    "    fear.append(emt['fear'])\n",
    "    happiness.append(emt['happiness'])\n",
    "    surprise.append(emt['surprise'])\n",
    "    sadness.append(emt['sadness'])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "writing(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deek=dict()\n",
    "deek['Name'] = query\n",
    "deek['anger']=anger\n",
    "deek['disgust']=disgust\n",
    "deek['happiness']=happiness\n",
    "deek['fear']=fear\n",
    "deek['surprise']=surprise\n",
    "deek['sadness']=sadness\n",
    "dataframe = pd.DataFrame(deek)\n",
    "dataframe.to_csv(\"C:/Users/hbg13/Desktop/카다뷔치/\"+query+ \" 감정 분석 결과.csv\",header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily\n",
    "deek"
   ]
  },
 
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
