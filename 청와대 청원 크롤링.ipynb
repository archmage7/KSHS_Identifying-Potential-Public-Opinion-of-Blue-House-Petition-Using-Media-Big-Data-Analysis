{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome import options\n",
    "from selenium import webdriver\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = options.Options()\n",
    "options.add_argument(r\"--headless\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok 68 1\n",
      "ok 68 2\n",
      "ok 68 3\n",
      "ok 68 4\n",
      "ok 68 5\n",
      "ok 68 6\n",
      "ok 68 7\n",
      "ok 68 8\n",
      "ok 68 9\n",
      "ok 68 10\n",
      "ok 68 11\n",
      "ok 68 12\n",
      "ok 68 13\n",
      "ok 68 14\n",
      "ok 68 15\n",
      "ok 69 1\n",
      "ok 69 2\n",
      "ok 69 3\n",
      "ok 69 4\n",
      "ok 69 5\n",
      "ok 69 6\n",
      "ok 69 7\n",
      "ok 69 8\n",
      "ok 69 9\n",
      "ok 69 10\n",
      "ok 69 11\n",
      "ok 69 12\n",
      "ok 69 13\n",
      "ok 69 14\n",
      "ok 69 15\n"
     ]
    }
   ],
   "source": [
    "# from 2018.08.15 광복절 30일간 (2018.09.14 까지)\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "# 크롤링 시간 : 매일 오후 9시 30분\n",
    "# 크롤링 할때 출력파일 이름 날짜로 변경하기\n",
    "# pip install fake-useragent\n",
    "# pip install selenium\n",
    "# chromedriver 깔고 저장경로 변경 \n",
    "# 출력 보고 None 뜨는거는 수동으로 ^^\n",
    "# 함태완 \n",
    "agrees=list()\n",
    "numbers=list()\n",
    "categorys=list()\n",
    "titles=list()\n",
    "dates=list()\n",
    "k=0\n",
    "# C:\\Users\\양현재_4\\Desktop\\chromedriver.exe\n",
    "# C:\\Users\\family\\Desktop\\chromedriver_win32\\chromedriver.exe\n",
    "for i in range(1, 70):\n",
    "    ua = str(UserAgent().random)\n",
    "    options.add_argument(r\"--{0}\".format(ua))\n",
    "    driver = webdriver.Chrome(r\"C:\\Users\\양현재_4\\Desktop\\chromedriver.exe\",\n",
    "                        chrome_options=options)\n",
    "    options.arguments.remove(r\"--{0}\".format(ua))\n",
    "    url=\"https://www1.president.go.kr/petitions?order=best&page=\"+str(i)\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(3)\n",
    "    soup=BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    for j in range(1, 16): \n",
    "        if i==1 and j<=10:\n",
    "            agree = soup.select(\"div.wrap > div.board.text > div.b_list.category > div.bl_body > ul > li:nth-of-type(\"+str(j)+\") > div > div.bl_agree.cs\")\n",
    "        else:\n",
    "            agree = soup.select(\"div.wrap > div.board.text > div.b_list.category > div.bl_body > ul > li:nth-of-type(\"+str(j)+\") > div > div.bl_agree.cb\")            \n",
    "        \n",
    "        if agree == []:\n",
    "            print(\"None \"+str(i)+\" \"+str(j))\n",
    "            continue\n",
    "        agree_text = (agree[0].getText())\n",
    "        agree_text = re.sub('[^0-9]', '', agree_text)\n",
    "        agrees.append(agree_text)\n",
    "        \n",
    "        number = soup.select(\"div.wrap > div.board.text > div.b_list.category > div.bl_body > ul > li:nth-of-type(\"+str(j)+\") > div > div.bl_no\")\n",
    "        nn = re.findall(\"\\d+\", number[0].getText())[0]\n",
    "        numbers.append(nn)\n",
    "\n",
    "        category = soup.select(\"div.wrap > div.board.text > div.b_list.category > div.bl_body > ul > li:nth-of-type(\"+str(j)+\") > div > div.bl_category.cs\")\n",
    "        categorys.append((category[0].getText())[3:])\n",
    "\n",
    "        title = soup.select(\"div.wrap > div.board.text > div.b_list.category > div.bl_body > ul > li:nth-of-type(\"+str(j)+\") > div > div.bl_subject > a\")\n",
    "        titles.append((title[0].getText())[3:])\n",
    "\n",
    "        date = soup.select(\"div.wrap > div.board.text > div.b_list.category > div.bl_body > ul > li:nth-of-type(\"+str(j)+\") > div > div.bl_date.light\")\n",
    "        dd = re.findall(\"\\d+\", date[0].getText())\n",
    "        ddd = \"\"\n",
    "        for num in dd:\n",
    "            ddd += num\n",
    "        dates.append(ddd)\n",
    "        print(\"ok \"+str(i)+\" \"+str(j))\n",
    "driver.close()\n",
    "d={\"번호\": numbers, \"분류\": categorys, \"제목\": titles, \"기간\": dates, \"동의자수\": agrees}\n",
    "df=pd.DataFrame(data=d)\n",
    "df.to_csv(\"20180816.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
